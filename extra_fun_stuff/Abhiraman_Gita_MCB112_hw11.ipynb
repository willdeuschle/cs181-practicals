{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCB 112 Homework 11\n",
    "Gita Abhiraman\n",
    "\n",
    "## Part 1: K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'w11-data.tbl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b1ab6415e3d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#read in the file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mall_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdata_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m#ignore header line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mdata_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'w11-data.tbl'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "import numpy.random as rand\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import scipy.spatial.distance as dis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "file_name=\"w11-data.tbl\"\n",
    "\n",
    "#read in the file\n",
    "all_info=[]\n",
    "with open(file_name, \"r\") as data_file:\n",
    "    #ignore header line\n",
    "    data_file.readline()\n",
    "    for line in data_file:\n",
    "        line_info=line.split()\n",
    "        all_info.append(tuple([float(line_info[i]) for i in range(len(line_info))]))\n",
    "\n",
    "coords=np.array(all_info)      \n",
    "\n",
    "log_coords = np.log(coords)\n",
    "\n",
    "# Define number of clusters\n",
    "num_clust = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed dimensions from 2 to 2001\n",
    "# note to grader: sometimes this doesn't run at first, but rerunning works\n",
    "\n",
    "def assignment(coords,centers):  \n",
    "    \n",
    "    '''\n",
    "    Return current cluster assigned to each point, as well as the \n",
    "    sum of this distances between each point and its assigned cluster\n",
    "    '''\n",
    "    \n",
    "    # Find minimum distance between a point and each center\n",
    "    coords = np.array(coords)\n",
    "    centers = np.array(centers)\n",
    "    \n",
    "    distances = np.zeros(200)\n",
    "    clusters = np.zeros(200)\n",
    "    \n",
    "    for j in range(0, 200):\n",
    "        best_dist = 10000000\n",
    "        for i in range(0, num_clust):\n",
    "            distance = 0\n",
    "            for k in range(0, 2001):\n",
    "                distance = distance + (coords[j][k]-centers[i][k])**2\n",
    "            distance = np.sqrt(distance)\n",
    "            if (distance < best_dist):\n",
    "                best_dist = distance\n",
    "                best_clust = i\n",
    "        distances[j] = best_dist\n",
    "        clusters[j] = best_clust\n",
    "        \n",
    "    # Count how many points in each cluster\n",
    "    c = Counter(clusters)\n",
    "    \n",
    "    # Look for empty clusters\n",
    "    for x in set(range(len(centers))).difference(set(c.keys())):\n",
    "        clusters,distances =  assign_empty(x,clusters,distances)\n",
    "        \n",
    "    distance = sum(distances)\n",
    "    return clusters, distance\n",
    "\n",
    "def assign_empty(c,clusters,distances):\n",
    "    \n",
    "    # find index of point furthest from its assigned center\n",
    "    max_idx = np.argmax(distances)\n",
    "    \n",
    "    # set distances at that index to 0\n",
    "    distances[max_idx] = 0\n",
    "    \n",
    "    # set clusters at that index to empty cluster\n",
    "    clusters[max_idx] = c\n",
    "    \n",
    "    return clusters,distances\n",
    "\n",
    "def update(coords, clusters, num_clust):\n",
    "    \n",
    "    '''\n",
    "    Calculates the new cluster centers as an average of the positions of all \n",
    "    points included in the cluster.\n",
    "    '''\n",
    "    \n",
    "    coords = np.asarray(coords)\n",
    "\n",
    "    # Find indices of each point assigned to each cluster\n",
    "\n",
    "    clustered_data = []\n",
    "    centers = []\n",
    "    for i in range(0,num_clust):\n",
    "        clustered_data.append([])\n",
    "        for j in range(0,200):\n",
    "            if clusters[j] == i:\n",
    "                clustered_data[i].append(coords[j])\n",
    "    \n",
    "    for x in range(0,num_clust):\n",
    "        center_coords = np.zeros(2001)\n",
    "        for i in range(2001):\n",
    "            center_coords[i]= np.mean(np.array(clustered_data[x])[:,i])\n",
    "        centers.append(center_coords)    \n",
    "    return(centers)\n",
    "    \n",
    "# Initalize best clusters\n",
    "min_dist = float('inf')\n",
    "clusters_best = []\n",
    "\n",
    "# Loop on iters until negligible change in min_dist\n",
    "\n",
    "while True:    \n",
    "    # Each iteration starts with a random set of centers\n",
    "    centers = rand.uniform(low = np.min(log_coords), high = np.max(log_coords), size=(num_clust,2001))\n",
    "    \n",
    "    # Start with empty clusters\n",
    "    clusters_old = []*len(log_coords)\n",
    "    clusters = [0]*len(log_coords)\n",
    "   \n",
    "    # Iterate until clusters don't change\n",
    "    old_dist = 0\n",
    "    while True:\n",
    "        # Update clusters\n",
    "\n",
    "        clusters_old = clusters\n",
    "        \n",
    "        # New Assignment \n",
    "        [clusters,distance] = assignment(log_coords,centers)        \n",
    "        \n",
    "        if (np.abs(distance - old_dist) < 0.1):\n",
    "            break\n",
    "            \n",
    "        # New centers\n",
    "        centers = update(log_coords, clusters, num_clust)\n",
    "        print('dist', distance)\n",
    "        old_dist=distance\n",
    "        \n",
    "    # Save clusters and centers if it has minimal sum distance to date\n",
    "    \n",
    "    if (distance < min_dist):  \n",
    "        min_dist = distance\n",
    "        centers_best = centers\n",
    "        clusters_best = clusters\n",
    "    \n",
    "    if ((min_dist - distance)<0.1):\n",
    "        break\n",
    "    \n",
    "print('min distance', min_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the k-means algorithm above, modified from pset 6 to include 2001 dimensions, I found the minimum distance to be about 4170, which is similar to what Watson found. I ran the algorithm until there was a change of less than 1 in the minimum distance.\n",
    "\n",
    "## Part 2\n",
    "\n",
    "Use singular value decomposition to find the principal components of the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords=np.array(all_info)      \n",
    "log_coords = np.log(coords)\n",
    "data = np.zeros(shape = (200,2001))\n",
    "\n",
    "# subtract mean from each data point\n",
    "for i in range(200):\n",
    "    for j in range(2001):\n",
    "        data[i,j] = log_coords[i,j] - np.mean(log_coords[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,S,W=np.linalg.svd(data)      \n",
    "\n",
    "# calculate eigenvalues\n",
    "eig = np.zeros(len(data))\n",
    "for i in range(len(data)):\n",
    "    eig[i]=(S[i]*S[i])/(len(data)-1)\n",
    "    \n",
    "# sort eigenvalues\n",
    "idx = np.argsort(eig)\n",
    "coeff = W[idx,:]\n",
    "\n",
    "# plot data projected onto PC1 and PC2\n",
    "plt.figure(1)\n",
    "plt.scatter(U[:,0], U[:,1])\n",
    "plt.title(\"Data projected onto PC1 and PC2\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.scatter(idx, eig[idx])\n",
    "plt.title(\"Plot of eigenvalues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name=\"w11-eigen.tbl\"\n",
    "\n",
    "#read in the file\n",
    "neg_data=[]\n",
    "with open(file_name, \"r\") as data_file:\n",
    "    #ignore header line\n",
    "    data_file.readline()\n",
    "    for line in data_file:\n",
    "        fields = line.split()\n",
    "        neg_data.append(float(fields[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "index = np.linspace(0, len(neg_data), len(neg_data))\n",
    "neg_data = np.array(neg_data)\n",
    "plt.scatter(index, neg_data)\n",
    "plt.title(\"Plot of negative data eigenvalues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine influential genes\n",
    "idx = np.argsort(eig)\n",
    "idx = idx[::-1]\n",
    "co = W[idx,:]\n",
    "plt.figure(4)\n",
    "plt.scatter(co[0,:], co[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_genes = []\n",
    "for i in range(200):\n",
    "    #print(co[0,i] + co[1,i])\n",
    "    if (co[0,i] + co[1,i] > 0.01):\n",
    "        impt_genes.append(i)\n",
    "\n",
    "        \n",
    "print('Number of important genes')\n",
    "print(len(impt_genes))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is reasonable to assume 8 clusters. We see 8 clusters emerge when we plot the projection onto the 2 principal components (figure 1). Focusing on the first two principal components is reasonable because the order of magnitude of eigenvalues quickly drops off (figure 2). This is in sharp contrast to the negative control data set, where all eigenvalues are the same order of magnitude and the decrease is linear (figure 3). \n",
    "\n",
    "Based on the eigenvector loadings, 46 genes appear to affect cell type when we count only those genes whose coefficients (for the first two principal components) sum to above a threshold of 0.01. \n",
    "\n",
    "\n",
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bad k-means from part 1\n",
    "colormap = ['xkcd:orange', 'xkcd:olive','xkcd:azure',    'xkcd:rose', 'xkcd:mustard', 'xkcd:peach',  'xkcd:turquoise', 'xkcd:lavender', 'xkcd:rust', 'xkcd:red']\n",
    "plt.figure()\n",
    "centers = np.array(centers)\n",
    "clusters = clusters.astype(int)\n",
    "Q = 8\n",
    "\n",
    "for k in range(1):\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(200):\n",
    "        edgecolor = colormap[clusters[i]]\n",
    "        fillcolor = 'w'\n",
    "        shape     = 'o'\n",
    "        ax.plot(U[i,0], U[i,1], marker=shape, mec=edgecolor, mfc=fillcolor, mew=1.5)\n",
    "\n",
    "    #for q in range(Q):\n",
    "        #ax.plot(np.array(centers)[q,0], np.array(centers)[q,1], '*k', ms=10)\n",
    "\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly this k-means is not working.\n",
    "\n",
    "Instead, a better method would be to run the k-means algorithm on the data projected onto the first two principal components, since we see 8 distinct clusters in that scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerun k-means on data projected in PC1, PC2\n",
    "# Note to grader: sometimes this works better if refreshed or run twice.\n",
    "\n",
    "def assignment(coords,centers):  \n",
    "    \n",
    "    '''\n",
    "    Return current cluster assigned to each point, as well as the \n",
    "    sum of this distances between each point and its assigned cluster\n",
    "    '''\n",
    "    # Find minimum distance between a point and each center\n",
    "    coords = np.array(coords)\n",
    "    centers = np.array(centers)\n",
    "    \n",
    "    distances = np.zeros(200)\n",
    "    clusters = np.zeros(200)\n",
    "    \n",
    "    for j in range(0, 200):\n",
    "        best_dist = 1000\n",
    "        for i in range(0, num_clust):\n",
    "            distance = 0\n",
    "            for k in range(0, 2):\n",
    "                distance = distance + (coords[j][k]-centers[i][k])**2\n",
    "            distance = np.sqrt(distance)\n",
    "            if (distance < best_dist):\n",
    "                best_dist = distance\n",
    "                best_clust = i\n",
    "        distances[j] = best_dist\n",
    "        clusters[j] = best_clust\n",
    "        \n",
    "    # Count how many points in each cluster\n",
    "    c = Counter(clusters)\n",
    "    \n",
    "    # Look for empty clusters\n",
    "    for x in set(range(len(centers))).difference(set(c.keys())):\n",
    "        clusters,distances =  assign_empty(x,clusters,distances)\n",
    "        \n",
    "    distance = sum(distances)\n",
    "    return clusters, distance\n",
    "\n",
    "\n",
    "def update(coords, clusters, num_clust):\n",
    "    \n",
    "    '''\n",
    "    Calculates the new cluster centers as an average of the positions of all \n",
    "    points included in the cluster.\n",
    "    '''\n",
    "    \n",
    "    coords = np.asarray(coords)\n",
    "    # Find indices of each point assigned to each cluster\n",
    "\n",
    "    clustered_data = []\n",
    "    centers = []\n",
    "    for i in range(0,num_clust):\n",
    "        clustered_data.append([])\n",
    "        for j in range(0,200):\n",
    "            if clusters[j] == i:\n",
    "                clustered_data[i].append(coords[j])\n",
    "    \n",
    "    for x in range(0,num_clust):\n",
    "        center_coords = np.zeros(2)\n",
    "        for i in range(2):\n",
    "            center_coords[i]= np.mean(np.array(clustered_data[x])[:,i])\n",
    "        centers.append(center_coords)    \n",
    "    return(centers)\n",
    "    \n",
    "\n",
    "while True:\n",
    "    # Each iteration starts with a random set of centers\n",
    "    centers = rand.uniform(low = np.min(U[:,0:2]), high = np.max(U[:,0:2]), size=(num_clust,2))\n",
    "    \n",
    "    # Start with empty clusters\n",
    "    clusters_old = []*len(log_coords)\n",
    "    clusters = [0]*len(log_coords)\n",
    "   \n",
    "    # Iterate until clusters don't change\n",
    "    old_dist = 0\n",
    "    min_dist = 100\n",
    "    #for i in range(100):\n",
    "    while True:\n",
    "        # Update clusters\n",
    "\n",
    "        clusters_old = clusters\n",
    "        \n",
    "        # New Assignment \n",
    "        [clusters,distance] = assignment(U[:,0:2],centers)        \n",
    "        \n",
    "        if (np.abs(distance - old_dist) < .01):\n",
    "            break\n",
    "            \n",
    "        # New centers\n",
    "        centers = update(U[:,0:2], clusters, num_clust)\n",
    "        print('dist', distance)\n",
    "        old_dist=distance\n",
    "        \n",
    "    # Save clusters and centers if it has minimal sum distance to date\n",
    "    \n",
    "    if (distance < min_dist):  \n",
    "        min_dist = distance\n",
    "        centers_best = centers\n",
    "        clusters_best = clusters\n",
    "    \n",
    "    if ((min_dist - distance)<.01):\n",
    "        break\n",
    "    \n",
    "print('min distance', min_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = ['xkcd:orange', 'xkcd:olive','xkcd:azure',    'xkcd:rose', 'xkcd:mustard', 'xkcd:peach',  'xkcd:turquoise', 'xkcd:lavender', 'xkcd:rust', 'xkcd:red']\n",
    "plt.figure()\n",
    "centers = np.array(centers)\n",
    "clusters = clusters.astype(int)\n",
    "Q = 8\n",
    "for k in range(1):\n",
    "    fig, ax = plt.subplots()\n",
    "    for i in range(200):\n",
    "        edgecolor = colormap[clusters[i]]\n",
    "        fillcolor = 'w'\n",
    "        shape     = 'o'\n",
    "        ax.plot(U[i,0], U[i,1], marker=shape, mec=edgecolor, mfc=fillcolor, mew=1.5)\n",
    "\n",
    "    #for q in range(Q):\n",
    "        #ax.plot(np.array(centers)[q,0], np.array(centers)[q,1], '*k', ms=10)\n",
    "\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better! Having re-run our k-means algorithm on the data projected into two principal components, the 8 clusters are different colors as we expect.\n",
    "\n",
    "## Part 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reconstruct data using first two principal components\n",
    "\n",
    "X_new = U[:, :2]@np.diag(S[:2])@W[:2,:]\n",
    "\n",
    "# Add only the genes determined to be important in part 2\n",
    "X_new_impt = []\n",
    "for i in range(len(impt_genes)):\n",
    "    X_new_impt.append(X_new[:,i])\n",
    "\n",
    "# Identify and append which cluster each sample belonged to\n",
    "row = np.zeros(200)\n",
    "for i in range(200):\n",
    "    row[i] = clusters[i]\n",
    "\n",
    "X_new_impt.append(row)\n",
    "X_new_impt = np.array(X_new_impt).transpose()\n",
    "\n",
    "# Sort the samples by cluster\n",
    "X_sorted = X_new_impt[X_new_impt[:,46].argsort()]\n",
    "X_sorted = X_sorted[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.pcolor(np.array(X_sorted), cmap = 'ocean')\n",
    "plt.xlabel('gene')\n",
    "plt.ylabel('sample')\n",
    "plt.title('Heatmap for important genes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters now look much more obvious in this heat map! You can see the delineations between the 8 clusters in the borders between rectangular patches. You can also tell that these 46 \"important genes\" have distinct expression patterns in the 8 different clusters. The patterns are much more clear once we group by the clusters assigned by the corrected k-means, when the data is projected into two principal components. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
